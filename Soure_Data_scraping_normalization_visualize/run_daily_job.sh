#!/bin/bash
# Script wrapper Ä‘á»ƒ cháº¡y Spark job hÃ ng ngÃ y vá»›i logging

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
cd "$SCRIPT_DIR"

# Táº¡o thÆ° má»¥c logs náº¿u chÆ°a cÃ³
LOG_DIR="$SCRIPT_DIR/logs"
mkdir -p "$LOG_DIR"

# TÃªn file log vá»›i timestamp
LOG_FILE="$LOG_DIR/job_$(date +%Y%m%d_%H%M%S).log"
ERROR_LOG="$LOG_DIR/job_errors.log"

# Activate virtual environment náº¿u cÃ³
if [ -f "venv/bin/activate" ]; then
    source venv/bin/activate
fi

# Ghi log báº¯t Ä‘áº§u
echo "========================================" >> "$LOG_FILE"
echo "ðŸš€ Báº¯t Ä‘áº§u Spark job: $(date '+%Y-%m-%d %H:%M:%S')" >> "$LOG_FILE"
echo "========================================" >> "$LOG_FILE"
echo "" >> "$LOG_FILE"

# Cháº¡y job vÃ  ghi log
python3 daily_gold_job_normalization_spark.py >> "$LOG_FILE" 2>&1
EXIT_CODE=$?

# Ghi log káº¿t thÃºc
echo "" >> "$LOG_FILE"
echo "========================================" >> "$LOG_FILE"
if [ $EXIT_CODE -eq 0 ]; then
    echo "âœ… Job hoÃ n táº¥t thÃ nh cÃ´ng: $(date '+%Y-%m-%d %H:%M:%S')" >> "$LOG_FILE"
else
    echo "âŒ Job tháº¥t báº¡i (exit code: $EXIT_CODE): $(date '+%Y-%m-%d %H:%M:%S')" >> "$LOG_FILE"
    # Ghi vÃ o error log
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] Job failed with exit code $EXIT_CODE" >> "$ERROR_LOG"
    echo "Log file: $LOG_FILE" >> "$ERROR_LOG"
    tail -20 "$LOG_FILE" >> "$ERROR_LOG"
    echo "---" >> "$ERROR_LOG"
fi
echo "========================================" >> "$LOG_FILE"

# Giá»¯ láº¡i chá»‰ 30 file log gáº§n nháº¥t
cd "$LOG_DIR"
ls -t job_*.log 2>/dev/null | tail -n +31 | xargs -r rm

exit $EXIT_CODE
